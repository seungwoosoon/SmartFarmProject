{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# YOLO í† ë§ˆí†  ì§ˆë³‘ ë¶„ë¥˜ ëª¨ë¸í•™ìŠµ"
      ],
      "metadata": {
        "id": "QQezx6STVABW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## í™˜ê²½ì„¤ì •"
      ],
      "metadata": {
        "id": "oVw-MRPLVIAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1ë‹¨ê³„: í™˜ê²½ ì„¤ì •\n",
        "print(\"ğŸš€ YOLOv8 í† ë§ˆí†  ì§ˆë³‘ ë¶„ë¥˜ - í•™ìŠµ ë…¸íŠ¸ë¶\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "print(\"ğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...\")\n",
        "!pip install ultralytics -q\n",
        "print(\"âœ… ultralytics ì„¤ì¹˜ ì™„ë£Œ\")\n",
        "\n",
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "from google.colab import drive\n",
        "\n",
        "# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n",
        "print(\"\\nğŸ“ êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸ ì¤‘...\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "print(\"âœ… êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸ ì™„ë£Œ\")\n",
        "\n",
        "# GPU ë° ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸\n",
        "print(f\"\\nğŸ’» ì‹œìŠ¤í…œ ì •ë³´:\")\n",
        "print(f\"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n"
      ],
      "metadata": {
        "id": "_eHfXt2NVG8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ë°ì´í„°ì…‹ ë° YAML íŒŒì¼ í™•ì¸"
      ],
      "metadata": {
        "id": "Qj3Zp0-AVOrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2ë‹¨ê³„: ë°ì´í„°ì…‹ ë° YAML íŒŒì¼ í™•ì¸\n",
        "print(f\"\\n=== ë°ì´í„°ì…‹ í™•ì¸ ===\")\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/dataset_6class_complete\"\n",
        "yaml_path = \"/content/drive/MyDrive/data_6class.yaml\"\n",
        "\n",
        "print(f\"ë°ì´í„°ì…‹ ê²½ë¡œ: {dataset_path}\")\n",
        "print(f\"YAML ê²½ë¡œ: {yaml_path}\")\n",
        "\n",
        "# ë°ì´í„°ì…‹ êµ¬ì¡° í™•ì¸\n",
        "if os.path.exists(dataset_path):\n",
        "    print(f\"âœ… ë°ì´í„°ì…‹ ì¡´ì¬ í™•ì¸\")\n",
        "    for part in ['newpart_01', 'newpart_02', 'newpart_03']:\n",
        "        part_dir = f\"{dataset_path}/{part}\"\n",
        "        if os.path.exists(part_dir):\n",
        "            img_count = len([f for f in os.listdir(part_dir) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "            txt_count = len([f for f in os.listdir(part_dir) if f.endswith('.txt')])\n",
        "            role = \"Train\" if part != 'newpart_03' else \"Val\"\n",
        "            print(f\"  {part}: ì´ë¯¸ì§€ {img_count}ê°œ, ë¼ë²¨ {txt_count}ê°œ ({role})\")\n",
        "else:\n",
        "    print(f\"âŒ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤: {dataset_path}\")\n",
        "    print(\"âš ï¸ í•™ìŠµì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "# YAML íŒŒì¼ í™•ì¸\n",
        "if os.path.exists(yaml_path):\n",
        "    print(f\"âœ… YAML íŒŒì¼ ì¡´ì¬ í™•ì¸\")\n",
        "    with open(yaml_path, 'r', encoding='utf-8') as f:\n",
        "        yaml_content = f.read()\n",
        "        print(f\"YAML ë‚´ìš©:\\n{yaml_content}\")\n",
        "else:\n",
        "    print(f\"âŒ YAML íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {yaml_path}\")\n",
        "    print(\"âš ï¸ í•™ìŠµì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. YAML íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n"
      ],
      "metadata": {
        "id": "5ePaoLz7VSeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## í•™ìŠµ ì‹¤í–‰ ì—¬ë¶€ í™•ì¸"
      ],
      "metadata": {
        "id": "RvD3Nci0VXdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3ë‹¨ê³„: í•™ìŠµ ì‹¤í–‰ ì—¬ë¶€ í™•ì¸ ë° ì•ˆì „ì¥ì¹˜\n",
        "def check_existing_training():\n",
        "    \"\"\"ê¸°ì¡´ í•™ìŠµ ê²°ê³¼ í™•ì¸ - ì¤‘ë³µ í•™ìŠµ ë°©ì§€\"\"\"\n",
        "    results_dir = '/content/drive/MyDrive/yolo_training_results/tomato_6class_v1'\n",
        "    weights_dir = f\"{results_dir}/weights\"\n",
        "\n",
        "    if os.path.exists(weights_dir):\n",
        "        weights = [f for f in os.listdir(weights_dir) if f.endswith('.pt')]\n",
        "        if weights:\n",
        "            print(f\"âš ï¸ ê¸°ì¡´ í•™ìŠµ ê²°ê³¼ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "            print(f\"ğŸ“‚ ìœ„ì¹˜: {weights_dir}\")\n",
        "            print(f\"ğŸ” ëª¨ë¸ íŒŒì¼ë“¤: {weights}\")\n",
        "\n",
        "            print(f\"\\nğŸ¤” ë‹¤ìŒ ì¤‘ ì„ íƒí•˜ì„¸ìš”:\")\n",
        "            print(f\"1. ìƒˆë¡œ í•™ìŠµí•˜ê¸° (ê¸°ì¡´ ê²°ê³¼ ë®ì–´ì“°ê¸°)\")\n",
        "            print(f\"2. ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©í•˜ê¸° (í•™ìŠµ ê±´ë„ˆë›°ê¸°)\")\n",
        "            print(f\"3. í•™ìŠµ ê²°ê³¼ë§Œ ë¶„ì„í•˜ê¸°\")\n",
        "\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# ê¸°ì¡´ í•™ìŠµ í™•ì¸\n",
        "existing_training = check_existing_training()"
      ],
      "metadata": {
        "id": "LzfFZPf8Vi7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YOLOv8 í•™ìŠµ ì‹œì‘"
      ],
      "metadata": {
        "id": "GjhXYm8GVmxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4ë‹¨ê³„: YOLOv8 í•™ìŠµ ì‹œì‘\n",
        "def start_training(force_retrain=False):\n",
        "    \"\"\"YOLO ëª¨ë¸ í•™ìŠµ ì‹¤í–‰\"\"\"\n",
        "\n",
        "    if existing_training and not force_retrain:\n",
        "        print(f\"\\nğŸ›‘ ê¸°ì¡´ í•™ìŠµ ê²°ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.\")\n",
        "        print(f\"ğŸ’¡ ìƒˆë¡œ í•™ìŠµí•˜ë ¤ë©´ start_training(force_retrain=True)ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\n=== YOLOv8 í•™ìŠµ ì‹œì‘ ===\")\n",
        "\n",
        "    if not os.path.exists(dataset_path) or not os.path.exists(yaml_path):\n",
        "        print(f\"âŒ ë°ì´í„°ì…‹ ë˜ëŠ” YAML íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")\n",
        "        return None\n",
        "\n",
        "    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # YOLOv8s ëª¨ë¸ ë¡œë“œ\n",
        "    model = YOLO('yolov8s.pt')\n",
        "    print(\"âœ… YOLOv8s ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
        "\n",
        "    # í•™ìŠµ ì‹œì‘\n",
        "    print(f\"\\nğŸš€ í•™ìŠµ ì‹œì‘! (ì˜ˆìƒ ì†Œìš” ì‹œê°„: 30-60ë¶„)\")\n",
        "    print(f\"ğŸ“Š í•™ìŠµ ì§„í–‰ ìƒí™©ì€ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.\")\n",
        "\n",
        "    results = model.train(\n",
        "        # ë°ì´í„° ì„¤ì •\n",
        "        data=yaml_path,\n",
        "\n",
        "        # í•™ìŠµ íŒŒë¼ë¯¸í„°\n",
        "        epochs=50,              # 50 ì—í¬í¬\n",
        "        imgsz=640,              # ì´ë¯¸ì§€ í¬ê¸°\n",
        "        batch=16,               # ë°°ì¹˜ í¬ê¸°\n",
        "        device=0,               # GPU ì‚¬ìš©\n",
        "\n",
        "        # ì¶œë ¥ ì„¤ì • (êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì €ì¥)\n",
        "        project='/content/drive/MyDrive/yolo_training_results',\n",
        "        name='tomato_6class_v1',\n",
        "\n",
        "        # ìµœì í™” íŒŒë¼ë¯¸í„°\n",
        "        optimizer='AdamW',       # ì˜µí‹°ë§ˆì´ì €\n",
        "        lr0=0.01,               # ì´ˆê¸° í•™ìŠµë¥ \n",
        "        warmup_epochs=3,        # ì›œì—… ì—í¬í¬\n",
        "\n",
        "        # validation ê´€ë ¨\n",
        "        conf=0.001,             # validation confidence threshold\n",
        "        iou=0.6,                # IoU threshold\n",
        "\n",
        "        # ì†ì‹¤ í•¨ìˆ˜ ê°€ì¤‘ì¹˜\n",
        "        box=7.5,                # ë°•ìŠ¤ ì†ì‹¤ ê°€ì¤‘ì¹˜\n",
        "        cls=0.5,                # ë¶„ë¥˜ ì†ì‹¤ ê°€ì¤‘ì¹˜\n",
        "        dfl=1.5,                # DFL ì†ì‹¤ ê°€ì¤‘ì¹˜\n",
        "\n",
        "        # ì €ì¥ ë° ë¡œê·¸ ì„¤ì •\n",
        "        save=True,              # ëª¨ë¸ ì €ì¥\n",
        "        save_period=10,         # 10 ì—í¬í¬ë§ˆë‹¤ ì €ì¥\n",
        "        plots=True,             # ê·¸ë˜í”„ ì €ì¥\n",
        "        val=True,               # ê²€ì¦ ìˆ˜í–‰\n",
        "\n",
        "        # ì¡°ê¸° ì¢…ë£Œ ë° ê¸°íƒ€\n",
        "        patience=20,            # ì¡°ê¸° ì¢…ë£Œ ê¸°ì¤€\n",
        "        exist_ok=True,          # ê¸°ì¡´ í´ë” ë®ì–´ì“°ê¸° í—ˆìš©\n",
        "        verbose=True            # ìƒì„¸ ë¡œê·¸\n",
        "    )\n",
        "\n",
        "    print(f\"\\nğŸ‰ í•™ìŠµ ì™„ë£Œ!\")\n",
        "    return results"
      ],
      "metadata": {
        "id": "c-jOZ0sPVqe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## í•™ìŠµ ê²°ê³¼ í™•ì¸ í•¨ìˆ˜"
      ],
      "metadata": {
        "id": "3YrlzF-QVvwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5ë‹¨ê³„: í•™ìŠµ ê²°ê³¼ í™•ì¸ í•¨ìˆ˜\n",
        "def check_training_results():\n",
        "    \"\"\"í•™ìŠµ ê²°ê³¼ ê¸°ë³¸ í™•ì¸\"\"\"\n",
        "    print(f\"\\n=== í•™ìŠµ ê²°ê³¼ í™•ì¸ ===\")\n",
        "\n",
        "    results_dir = '/content/drive/MyDrive/yolo_training_results/tomato_6class_v1'\n",
        "    weights_dir = f\"{results_dir}/weights\"\n",
        "\n",
        "    if os.path.exists(weights_dir):\n",
        "        weights = [f for f in os.listdir(weights_dir) if f.endswith('.pt')]\n",
        "        print(f\"âœ… ì €ì¥ëœ ê°€ì¤‘ì¹˜: {weights}\")\n",
        "\n",
        "        # best.pt ëª¨ë¸ë¡œ ìµœì¢… ê²€ì¦\n",
        "        if 'best.pt' in weights:\n",
        "            best_model_path = f\"{weights_dir}/best.pt\"\n",
        "            print(f\"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_path}\")\n",
        "\n",
        "            # ìµœì¢… ëª¨ë¸ ë¡œë“œ ë° ê²€ì¦\n",
        "            best_model = YOLO(best_model_path)\n",
        "\n",
        "            # Validation ì‹¤í–‰\n",
        "            val_results = best_model.val(\n",
        "                data=yaml_path,\n",
        "                conf=0.001,\n",
        "                iou=0.6,\n",
        "                device=0\n",
        "            )\n",
        "\n",
        "            print(f\"\\nğŸ“Š ìµœì¢… ì„±ëŠ¥:\")\n",
        "            print(f\"mAP@0.5: {val_results.box.map50:.4f}\")\n",
        "            print(f\"mAP@0.5:0.95: {val_results.box.map:.4f}\")\n",
        "\n",
        "            # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥\n",
        "            class_names = ['ì •ìƒ', 'í† ë§ˆí† ì¿ë¹›ê³°íŒ¡ì´ë³‘', 'í† ë§ˆí† í°ê°€ë£¨ë³‘',\n",
        "                          'ë‹¤ëŸ‰ì›ì†Œê²°í•(N)', 'ë‹¤ëŸ‰ì›ì†Œê²°í•(P)', 'ë‹¤ëŸ‰ì›ì†Œê²°í•(K)']\n",
        "\n",
        "            if hasattr(val_results.box, 'ap') and len(val_results.box.ap) > 0:\n",
        "                print(f\"\\nğŸ“ˆ í´ë˜ìŠ¤ë³„ mAP@0.5:\")\n",
        "                for i, name in enumerate(class_names):\n",
        "                    if i < len(val_results.box.ap):\n",
        "                        ap_value = val_results.box.ap[i] if val_results.box.ap[i] is not None else 0.0\n",
        "                        print(f\"  {name}: {ap_value:.4f}\")\n",
        "\n",
        "        print(f\"\\nğŸ“‚ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {results_dir}\")\n",
        "        print(f\"   - ê°€ì¤‘ì¹˜: {weights_dir}\")\n",
        "        print(f\"   - ê·¸ë˜í”„ ë° ë¡œê·¸: {results_dir}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"âŒ í•™ìŠµ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        print(f\"ğŸ’¡ í•™ìŠµì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”: start_training()\")\n"
      ],
      "metadata": {
        "id": "ctEMTA6rVxM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## í•™ìŠµ ê²°ê³¼ ìƒì„¸ ë¶„ì„"
      ],
      "metadata": {
        "id": "qQsYxQZlV1IU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6ë‹¨ê³„: í•™ìŠµ ê²°ê³¼ ìƒì„¸ ë¶„ì„\n",
        "def analyze_training_results():\n",
        "    \"\"\"í•™ìŠµ ê²°ê³¼ ìƒì„¸ ë¶„ì„ - ê³¼ì í•© ì—¬ë¶€ íŒë‹¨\"\"\"\n",
        "    print(\"ğŸ“Š í•™ìŠµ ê²°ê³¼ ìƒì„¸ ë¶„ì„ ì‹œì‘!\")\n",
        "\n",
        "    results_dir = '/content/drive/MyDrive/yolo_training_results/tomato_6class_v1'\n",
        "    results_csv = f\"{results_dir}/results.csv\"\n",
        "\n",
        "    if not os.path.exists(results_csv):\n",
        "        print(f\"âŒ results.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {results_csv}\")\n",
        "        print(f\"ğŸ’¡ í•™ìŠµì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n",
        "        return None\n",
        "\n",
        "    # CSV ì½ê¸°\n",
        "    df = pd.read_csv(results_csv)\n",
        "    print(f\"âœ… ì´ {len(df)}ê°œ ì—í¬í¬ í•™ìŠµ ì™„ë£Œ\")\n",
        "\n",
        "    # mAP íŠ¸ë Œë“œ ë¶„ì„\n",
        "    map50_col = None\n",
        "    if 'metrics/mAP50(B)' in df.columns:\n",
        "        map50_col = 'metrics/mAP50(B)'\n",
        "    elif 'val/mAP50' in df.columns:\n",
        "        map50_col = 'val/mAP50'\n",
        "\n",
        "    if map50_col:\n",
        "        map50_values = df[map50_col].values\n",
        "        best_map50 = max(map50_values)\n",
        "        best_epoch = df[df[map50_col] == best_map50].index[0] + 1\n",
        "        last_map50 = map50_values[-1]\n",
        "\n",
        "        print(f\"\\nğŸ“Š ì„±ëŠ¥ ìš”ì•½:\")\n",
        "        print(f\"  ìµœê³  mAP50: {best_map50:.4f} (ì—í¬í¬ {best_epoch})\")\n",
        "        print(f\"  ìµœì¢… mAP50: {last_map50:.4f}\")\n",
        "        print(f\"  ì„±ëŠ¥ ì°¨ì´: {(best_map50 - last_map50):.4f}\")\n",
        "\n",
        "        # ê³¼ì í•© íŒë‹¨\n",
        "        if best_map50 - last_map50 > 0.02:\n",
        "            print(\"ğŸš¨ ê³¼ì í•© ì˜ì‹¬: ìµœê³  ì„±ëŠ¥ ëŒ€ë¹„ 2% ì´ìƒ í•˜ë½\")\n",
        "            print(\"ğŸ’¡ ê¶Œì¥: best.pt ëª¨ë¸ ì‚¬ìš©\")\n",
        "        elif best_map50 - last_map50 > 0.01:\n",
        "            print(\"âš ï¸ ê²½ë¯¸í•œ ê³¼ì í•© ê°€ëŠ¥ì„±: 1-2% í•˜ë½\")\n",
        "        else:\n",
        "            print(\"âœ… ê³¼ì í•© ì—†ìŒ: ì„±ëŠ¥ ì•ˆì •ì \")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "CSKp14GlV209"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## í•™ìŠµ ê³¡ì„  ì‹œê°í™”"
      ],
      "metadata": {
        "id": "eANlK4IuV7tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7ë‹¨ê³„: í•™ìŠµ ê³¡ì„  ì‹œê°í™”\n",
        "def plot_training_curves(df=None):\n",
        "    \"\"\"í•™ìŠµ ê³¡ì„  ì‹œê°í™”\"\"\"\n",
        "    if df is None:\n",
        "        results_csv = '/content/drive/MyDrive/yolo_training_results/tomato_6class_v1/results.csv'\n",
        "        if not os.path.exists(results_csv):\n",
        "            print(f\"âŒ í•™ìŠµ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            return\n",
        "        df = pd.read_csv(results_csv)\n",
        "\n",
        "    print(f\"\\n=== í•™ìŠµ ê³¡ì„  ì‹œê°í™” ===\")\n",
        "\n",
        "    # ì „ë¬¸ì ì¸ 4ê°œ ì„œë¸Œí”Œë¡¯ êµ¬ì„±\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('Training Results Summary', fontsize=16, fontweight='bold')\n",
        "\n",
        "    epochs = range(len(df))\n",
        "\n",
        "    # 1. mAP50 ì§„í–‰\n",
        "    if 'metrics/mAP50(B)' in df.columns:\n",
        "        ax1 = axes[0, 0]\n",
        "        ax1.plot(epochs, df['metrics/mAP50(B)'], color='#1f77b4', linewidth=2, label='mAP50')\n",
        "        ax1.set_title('mAP50 ì§„í–‰', fontsize=14, fontweight='bold')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('mAP50')\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.legend()\n",
        "\n",
        "        # ìµœê³ ì  í‘œì‹œ\n",
        "        best_idx = df['metrics/mAP50(B)'].idxmax()\n",
        "        best_value = df['metrics/mAP50(B)'].iloc[best_idx]\n",
        "        ax1.plot(best_idx, best_value, 'ro', markersize=8)\n",
        "        ax1.text(best_idx, best_value + 0.02, f'Best: {best_value:.3f}',\n",
        "                ha='center', fontweight='bold')\n",
        "\n",
        "    # 2. mAP50-95 ì§„í–‰\n",
        "    if 'metrics/mAP50-95(B)' in df.columns:\n",
        "        ax2 = axes[0, 1]\n",
        "        ax2.plot(epochs, df['metrics/mAP50-95(B)'], color='#2ca02c', linewidth=2, label='mAP50-95')\n",
        "        ax2.set_title('mAP50-95 ì§„í–‰', fontsize=14, fontweight='bold')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.set_ylabel('mAP50-95')\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        ax2.legend()\n",
        "\n",
        "    # 3. Loss ì§„í–‰\n",
        "    ax3 = axes[1, 0]\n",
        "    train_loss_cols = [col for col in df.columns if 'train' in col and 'loss' in col]\n",
        "    val_loss_cols = [col for col in df.columns if 'val' in col and 'loss' in col]\n",
        "\n",
        "    if train_loss_cols and val_loss_cols:\n",
        "        ax3.plot(epochs, df[train_loss_cols[0]], color='#d62728', linewidth=2, label='Train Loss')\n",
        "        ax3.plot(epochs, df[val_loss_cols[0]], color='#ff7f0e', linewidth=2, label='Val Loss')\n",
        "        ax3.set_title('Loss ì§„í–‰', fontsize=14, fontweight='bold')\n",
        "        ax3.set_xlabel('Epoch')\n",
        "        ax3.set_ylabel('Loss')\n",
        "        ax3.grid(True, alpha=0.3)\n",
        "        ax3.legend()\n",
        "\n",
        "    # 4. ìµœê·¼ ì„±ëŠ¥ ìƒì„¸\n",
        "    ax4 = axes[1, 1]\n",
        "    if 'metrics/mAP50(B)' in df.columns:\n",
        "        recent_epochs = min(10, len(df))\n",
        "        recent_data = df['metrics/mAP50(B)'].tail(recent_epochs)\n",
        "        recent_x = range(len(df) - recent_epochs, len(df))\n",
        "\n",
        "        ax4.plot(recent_x, recent_data, 'o-', color='#9467bd', linewidth=2,\n",
        "                markersize=6, label=f'Recent {recent_epochs} epochs')\n",
        "        ax4.set_title(f'ìµœê·¼ {recent_epochs} ì—í¬í¬ ìƒì„¸', fontsize=14, fontweight='bold')\n",
        "        ax4.set_xlabel('Epoch')\n",
        "        ax4.set_ylabel('mAP50')\n",
        "        ax4.grid(True, alpha=0.3)\n",
        "        ax4.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/training_analysis_complete.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"ğŸ“ˆ í•™ìŠµ ê³¡ì„  ì €ì¥: /content/drive/MyDrive/training_analysis_complete.png\")\n"
      ],
      "metadata": {
        "id": "eReXPnLnV9Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ê°„ë‹¨í•œ ì¶”ë¡  í…ŒìŠ¤íŠ¸"
      ],
      "metadata": {
        "id": "Jz4d_tBRWAU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8ë‹¨ê³„: ê°„ë‹¨í•œ ì¶”ë¡  í…ŒìŠ¤íŠ¸\n",
        "def quick_inference_test():\n",
        "    \"\"\"í•™ìŠµ ì™„ë£Œ í›„ ê°„ë‹¨í•œ ì¶”ë¡  í…ŒìŠ¤íŠ¸\"\"\"\n",
        "    print(f\"\\n=== ê°„ë‹¨í•œ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ===\")\n",
        "\n",
        "    best_model_path = '/content/drive/MyDrive/yolo_training_results/tomato_6class_v1/weights/best.pt'\n",
        "\n",
        "    if not os.path.exists(best_model_path):\n",
        "        print(f\"âŒ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.\")\n",
        "        return\n",
        "\n",
        "    model = YOLO(best_model_path)\n",
        "\n",
        "    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì„ íƒ\n",
        "    val_dir = \"/content/drive/MyDrive/dataset_6class_complete/newpart_03\"\n",
        "    if os.path.exists(val_dir):\n",
        "        val_images = [f for f in os.listdir(val_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        if val_images:\n",
        "            test_image = f\"{val_dir}/{val_images[0]}\"\n",
        "            print(f\"ğŸ“· í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {val_images[0]}\")\n",
        "\n",
        "            # ì¶”ë¡  ì‹¤í–‰\n",
        "            results = model(test_image, conf=0.25, device=0)\n",
        "\n",
        "            # ê²°ê³¼ ì¶œë ¥\n",
        "            for r in results:\n",
        "                if r.boxes is not None and len(r.boxes) > 0:\n",
        "                    print(f\"âœ… {len(r.boxes)}ê°œ ê°ì²´ ê²€ì¶œ ì„±ê³µ!\")\n",
        "                    for i, box in enumerate(r.boxes):\n",
        "                        class_id = int(box.cls[0])\n",
        "                        confidence = float(box.conf[0])\n",
        "                        class_name = model.names[class_id]\n",
        "                        print(f\"  {i+1}. {class_name} (ì‹ ë¢°ë„: {confidence:.3f})\")\n",
        "                else:\n",
        "                    print(f\"âŒ ê²€ì¶œëœ ê°ì²´ ì—†ìŒ\")\n",
        "\n",
        "            print(f\"ğŸ¯ ìƒì„¸í•œ ì¶”ë¡  í…ŒìŠ¤íŠ¸ëŠ” Inference ë…¸íŠ¸ë¶ì„ ì‚¬ìš©í•˜ì„¸ìš”!\")"
      ],
      "metadata": {
        "id": "nmpcwhWHWBhw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}