{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"11YNcPESGq7P4go0VPPTBUCbbmEl7XqTK","authorship_tag":"ABX9TyO4hzeD+A4AH78HSh3IM5nP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"b902dc0c"},"source":["# Task\n","Combine data from JSON files within the \"file_attributes\" and \"growth_indicators\" fields located in the \"/content/drive/MyDrive/착과군/tom1\" through \"/content/drive/MyDrive/착과군/tom6\" folders into separate Excel files for each \"tom\" folder, with each variable as a column and each JSON file's data as a row."]},{"cell_type":"markdown","metadata":{"id":"2379ceae"},"source":["## Authenticate google drive\n","\n","### Subtask:\n","Mount Google Drive to access files.\n"]},{"cell_type":"markdown","metadata":{"id":"10552b4c"},"source":["**Reasoning**:\n","Mount Google Drive to access the files stored there.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c710893b","executionInfo":{"status":"ok","timestamp":1754741928226,"user_tz":-540,"elapsed":16835,"user":{"displayName":"오연희","userId":"00429706788097700036"}},"outputId":"e3ea7f77-60db-4c6a-9e19-c7820874413e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"7c630c14"},"source":["## Define input and output paths\n","\n","### Subtask:\n","Specify the base directory in Google Drive and the output directory for Excel files.\n"]},{"cell_type":"markdown","metadata":{"id":"19c00bdf"},"source":["**Reasoning**:\n","Define the base and output directories, and create the output directory if it doesn't exist.\n","\n"]},{"cell_type":"code","metadata":{"id":"cfa54605"},"source":["# 착과군에 대한 데이터셋 업로드할 폴더 생성\n","\n","import os\n","\n","base_dir = '/content/drive/MyDrive/착과군'\n","output_dir = '/content/drive/MyDrive/착과군/output_excel_files'\n","\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(f\"Base directory: {base_dir}\")\n","print(f\"Output directory: {output_dir}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a32d735b"},"source":["## Iterate through 'tom' folders\n","\n","### Subtask:\n","Loop through each folder from 'tom1' to 'tom6'.\n"]},{"cell_type":"markdown","metadata":{"id":"9c093ece"},"source":["**Reasoning**:\n","Create a list of folder names and iterate through them as instructed.\n","\n"]},{"cell_type":"code","metadata":{"id":"b0030057"},"source":["# 총 6개의 농장별 토마토 생장 데이터 저장 폴더 생성\n","\n","folder_names = [f'tom{i}' for i in range(1, 7)]\n","\n","for folder_name in folder_names:\n","    print(f\"Processing folder: {folder_name}\")\n","    # The next steps will involve processing the files within this folder\n","    # For now, just print the folder name to confirm the loop is working"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cdf13f41"},"source":["## Process json files in each folder\n","\n","### Subtask:\n","For each folder, find all JSON files.\n"]},{"cell_type":"markdown","metadata":{"id":"0b8edf4f"},"source":["**Reasoning**:\n","Iterate through the specified folders and find all JSON files within each folder.\n","\n"]},{"cell_type":"code","metadata":{"id":"4704c429"},"source":["# 섞여있는 json파일들을 농장별로 그룹화함\n","\n","import os\n","\n","folder_names = [f'tom{i}' for i in range(1, 7)]\n","\n","for folder_name in folder_names:\n","    print(f\"Processing folder: {folder_name}\")\n","    folder_path = os.path.join(base_dir, folder_name)\n","    entries = os.listdir(folder_path)\n","    json_files = [entry for entry in entries if entry.endswith('.json')]\n","    print(f\"Found JSON files: {json_files}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1c709a8e"},"source":["## Extract data from json files\n","\n","### Subtask:\n","Read each JSON file and extract the required variables from \"file_attributes\" and \"growth_indicators\".\n"]},{"cell_type":"markdown","metadata":{"id":"0ecef81c"},"source":["**Reasoning**:\n","Read each JSON file, extract the required data from \"file_attributes\" and \"growth_indicators\", and store it in a list of dictionaries.\n","\n"]},{"cell_type":"code","metadata":{"id":"ed0ee675"},"source":["# json에서 토마토 개체에 대한 정보를 얻을 수 있는 file attribute와\n","# 각 토마토의 생장에 대한 정보를 얻기 위한 growth indicator의 추츌할 요소들 선정\n","\n","import json\n","\n","folder_names = [f'tom{i}' for i in range(1, 7)]\n","\n","for folder_name in folder_names:\n","    print(f\"Processing folder: {folder_name}\")\n","    folder_path = os.path.join(base_dir, folder_name)\n","    entries = os.listdir(folder_path)\n","    json_files = [entry for entry in entries if entry.endswith('.json')]\n","\n","    all_data = []  # List to store data for the current folder\n","\n","    for json_file in json_files:\n","        file_path = os.path.join(folder_path, json_file)\n","        with open(file_path, 'r') as f:\n","            data = json.load(f)\n","\n","        extracted_data = {}\n","        if 'file_attributes' in data:\n","            extracted_data.update(data['file_attributes'])\n","        if 'growth_indicators' in data:\n","            extracted_data.update(data['growth_indicators'])\n","\n","        all_data.append(extracted_data)\n","\n","    # At this point, all_data contains the extracted data for the current folder.\n","    # The next step will be to convert this to a DataFrame and save it to Excel.\n","    print(f\"Extracted data for {len(all_data)} JSON files in {folder_name}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6d7cd2a9"},"source":["## Create a dataframe\n","\n","### Subtask:\n","Organize the extracted data into a pandas DataFrame.\n"]},{"cell_type":"markdown","metadata":{"id":"088a1e08"},"source":["**Reasoning**:\n","Convert the extracted data for the current folder into a pandas DataFrame and display the head of the DataFrame.\n","\n"]},{"cell_type":"code","metadata":{"id":"a8104ebb"},"source":["# 각 json파일에서 file_attribute와 growth indicator에 해당하는 칼럼 값들을 추출하여 excel파일에 정리\n","\n","import pandas as pd\n","import os # Import os to use os.path.join\n","\n","folder_names = [f'tom{i}' for i in range(1, 7)]\n","\n","for folder_name in folder_names:\n","    print(f\"Processing folder: {folder_name}\")\n","    folder_path = os.path.join(base_dir, folder_name)\n","    entries = os.listdir(folder_path)\n","    json_files = [entry for entry in entries if entry.endswith('.json')]\n","\n","    all_data = []  # List to store data for the current folder\n","\n","    for json_file in json_files:\n","        file_path = os.path.join(folder_path, json_file)\n","        with open(file_path, 'r') as f:\n","            data = json.load(f)\n","\n","        extracted_data = {}\n","        if 'file_attributes' in data:\n","            extracted_data.update(data['file_attributes'])\n","        if 'growth_indicators' in data:\n","            extracted_data.update(data['growth_indicators'])\n","\n","        all_data.append(extracted_data)\n","\n","    df = pd.DataFrame(all_data)\n","    print(f\"DataFrame for {folder_name}:\")\n","    display(df.head())\n","\n","    # Move the saving to excel code inside the loop\n","    output_filename = f\"{folder_name}.xlsx\"\n","    output_filepath = os.path.join(output_dir, output_filename)\n","    df.to_excel(output_filepath, index=False)\n","    print(f\"Successfully saved {folder_name} data to {output_filepath}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ef452d75"},"source":["## Write dataframe to excel\n","\n","### Subtask:\n","Save the DataFrame to an Excel file named after the 'tom' folder.\n"]},{"cell_type":"markdown","metadata":{"id":"b84da409"},"source":["**Reasoning**:\n","Construct the output file path and save the DataFrame to an Excel file.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7c73983c","executionInfo":{"status":"ok","timestamp":1754742625451,"user_tz":-540,"elapsed":995,"user":{"displayName":"오연희","userId":"00429706788097700036"}},"outputId":"e4435692-0e18-488b-aaa2-c0181e869881"},"source":["# 추출 완료 후 각각 tom농장에 대한 excel 파일 생성\n","\n","output_filename = f\"{folder_name}.xlsx\"\n","output_filepath = os.path.join(output_dir, output_filename)\n","df.to_excel(output_filepath, index=False)\n","print(f\"Successfully saved {folder_name} data to {output_filepath}\")"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully saved tom6 data to /content/drive/MyDrive/착과군/output_excel_files/tom6.xlsx\n"]}]},{"cell_type":"markdown","metadata":{"id":"1d3753a3"},"source":["## Summary:\n","\n","### Data Analysis Key Findings\n","\n","*   The process successfully extracted data from the `file_attributes` and `growth_indicators` fields of JSON files located within the `tom1` through `tom6` folders.\n","*   Data from each JSON file was organized into a row in a pandas DataFrame, with the variables from the extracted fields becoming the columns.\n","*   Separate Excel files were generated for each \"tom\" folder (`tom1.xlsx` through `tom6.xlsx`), containing the combined data from the JSON files within that folder.\n","\n","### Insights or Next Steps\n","\n","*   The structured Excel files are now ready for further analysis or integration into other workflows.\n","*   Consider adding error handling for potential issues like missing fields in JSON files or file read errors.\n"]},{"cell_type":"markdown","metadata":{"id":"f1ea445d"},"source":["# Task\n","Sort the Excel files located at \"/content/drive/MyDrive/착과군/output_excel_files/tom1.xlsx\" through \"/content/drive/MyDrive/착과군/output_excel_files/tom6.xlsx\" by the columns 'number', 'week', and 'fruitingNode' in ascending order."]},{"cell_type":"markdown","metadata":{"id":"3e9153ba"},"source":["## Iterate through 'tom' folders\n","\n","### Subtask:\n","Loop through each folder name from 'tom1' to 'tom6'.\n"]},{"cell_type":"markdown","metadata":{"id":"8fc3781b"},"source":["**Reasoning**:\n","Iterate through the specified folders.\n","\n"]},{"cell_type":"code","metadata":{"id":"b363fd7b"},"source":["folder_names = [f'tom{i}' for i in range(1, 7)]\n","\n","for folder_name in folder_names:\n","    print(f\"Processing folder: {folder_name}\")\n","    # The subsequent steps will involve reading, sorting, and saving the Excel file"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5cada228"},"source":["**Reasoning**:\n","Construct the full path to the Excel file for the current folder.\n","\n"]},{"cell_type":"code","metadata":{"id":"62df7d7b"},"source":["import os\n","\n","folder_names = [f'tom{i}' for i in range(1, 7)]\n","output_dir = '/content/drive/MyDrive/착과군/output_excel_files'\n","\n","for folder_name in folder_names:\n","    print(f\"Processing folder: {folder_name}\")\n","    output_filename = f\"{folder_name}.xlsx\"\n","    output_filepath = os.path.join(output_dir, output_filename)\n","    print(f\"Processing file: {output_filepath}\")\n","    # The next steps will involve reading the Excel file"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"12564bcb"},"source":["**Reasoning**:\n","Read the Excel file into a pandas DataFrame.\n","\n"]},{"cell_type":"code","metadata":{"id":"023cfe5e"},"source":["# excel파일을 읽어서 dataframe 생성\n","import pandas as pd\n","import os\n","\n","folder_names = [f'tom{i}' for i in range(1, 7)]\n","output_dir = '/content/drive/MyDrive/착과군/output_excel_files'\n","\n","for folder_name in folder_names:\n","    print(f\"Processing folder: {folder_name}\")\n","    output_filename = f\"{folder_name}.xlsx\"\n","    output_filepath = os.path.join(output_dir, output_filename)\n","    print(f\"Processing file: {output_filepath}\")\n","    df = pd.read_excel(output_filepath)\n","    print(f\"Read {len(df)} rows from {output_filename}\")\n","    # The next steps will involve sorting and saving the DataFrame"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1d897b1d"},"source":["**Reasoning**:\n","Sort the DataFrame by the specified columns.\n","\n"]},{"cell_type":"code","metadata":{"id":"1d10d4cd"},"source":["# tom농장별 excel파일을 읽어서 토마토 개체별, 주차별, 착과마디의 우선순위로 정렬\n","folder_names = [f'tom{i}' for i in range(1, 7)]\n","output_dir = '/content/drive/MyDrive/착과군/output_excel_files'\n","\n","for folder_name in folder_names:\n","    print(f\"Processing folder: {folder_name}\")\n","    output_filename = f\"{folder_name}.xlsx\"\n","    output_filepath = os.path.join(output_dir, output_filename)\n","    print(f\"Processing file: {output_filepath}\")\n","    df = pd.read_excel(output_filepath)\n","    print(f\"Read {len(df)} rows from {output_filename}\")\n","\n","    df_sorted = df.sort_values(by=['number', 'week', 'fruitingNode'], ascending=True)\n","    print(f\"Sorted DataFrame for {folder_name}\")\n","    # The next steps will involve saving the sorted DataFrame"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"51735911"},"source":["**Reasoning**:\n","Save the sorted DataFrame back to the original Excel file, overwriting the unsorted file.\n","\n"]},{"cell_type":"code","metadata":{"id":"31c0e2a9"},"source":["# 새로 정렬된 excel파일로 이전의 데이터 파일 덮어쓰기\n","folder_names = [f'tom{i}' for i in range(1, 7)]\n","output_dir = '/content/drive/MyDrive/착과군/output_excel_files'\n","\n","for folder_name in folder_names:\n","    print(f\"Processing folder: {folder_name}\")\n","    output_filename = f\"{folder_name}.xlsx\"\n","    output_filepath = os.path.join(output_dir, output_filename)\n","    print(f\"Processing file: {output_filepath}\")\n","    df = pd.read_excel(output_filepath)\n","    print(f\"Read {len(df)} rows from {output_filename}\")\n","\n","    df_sorted = df.sort_values(by=['number', 'week', 'fruitingNode'], ascending=True)\n","    print(f\"Sorted DataFrame for {folder_name}\")\n","\n","    df_sorted.to_excel(output_filepath, index=False)\n","    print(f\"Successfully saved sorted data to {output_filepath}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d0af420f"},"source":["## Summary:\n","\n","### Data Analysis Key Findings\n","\n","*   The analysis successfully iterated through six Excel files named `tom1.xlsx` through `tom6.xlsx` located in the specified directory.\n","*   Each Excel file was read into a pandas DataFrame.\n","*   Each DataFrame was sorted in ascending order based on the columns 'number', 'week', and 'fruitingNode'.\n","*   The sorted data was successfully saved back to the original Excel files, overwriting the unsorted content.\n","\n","### Insights or Next Steps\n","\n","*   The sorting process was completed successfully for all specified files, ensuring the data within each file is ordered according to the required columns.\n","*   No further steps are immediately required for this specific sorting task, as the data has been successfully processed and saved.\n"]}]}